\chapter{Implementation}

The implementation of the project required a new tool to be made that is the web crawler. The SPIMI program that was used in the previous was mostly left unchanged except for the addition of the tf-idf ranking technique.

\section{Web Crawlers}

\par The framework that was used to build the web crawler to scrape the required domain was Scrapy \cite{scrapy}. Scrapy is Python library which takes care of crawling websites following the proper etiquette. Scrapy also offers a powerful scraping module which allows us to extract with ease the text from the HTML page that we want.

\par Scrapy is run by executing the following command adding 
\begin{verbatim}
    scrapy crawl name_of_spider [-s CLOSESPIDER_PAGECOUNT = #]
\end{verbatim}

\subsection{Concordia Crawler}

\par The crawler was made to start from the \url{https://concordia.ca/ research.html} link. Since these resources are HTML files I've decided to consider the content of the paragraphs and headings tags. The crawler was implemented to save the document to a file with the number of the link. The number and the link was then saved in a separate file to be able to retrieve the link for queries.
\par Unfortunately, after my first attempt to crawl \url{https://concordia.ca/research.html} the crawl was stuck in some kind of loop when crawling the \url{https://www.concordia.ca/research/lifestyle-addiction/tools/scientific-monitoring.html}. It ended up making roughly 10 000 requests with only changing the query string. So I decided to deny the crawler to crawl this link in hopes to make the crawl proceeding in crawling other resources.
\par With the updated crawler, I was able to crawl 83 690 documents where their URL either contained news, research or next-gen. The previous requirements of the URL for it to be crawled was manually determined to limit the information that would not be related to artificial intelligence.
\par The content of the page that were scrape are the headings and the paragraphs inside the main-content of the site. This made sure that navigation section, footer and other parts of the website which do not change from page to page were ignore as the user information need would not be answered by the content found in those parts.

\subsection{AITopics Crawler}

\par The crawler was made to start from the \url{https://concordia.ca/search} link and extract artificial research related keywords. This website includes a section which categorized all articles under a certain technology. Since the since index needed to be related to artificial intelligence I decided to limit the crawling to the artificial intelligence articles.
\par Since we were only to extract keywords related to artificial intelligence research the crawling of the articles content was not constructive in the objective of the index. This is where the concept tags that AITopics assigns to articles are useful. The crawler was programed in extracting the concept tags from all articles and these would be used as the documents for the index.
\par The df values were compiled using the SPIMI then traversed through the entire index and save the df for each term to be used later in the ConcordiaAI index. To see the compiled df value please refer to the document bellow
\begin{verbatim}
    /indices/AIindex/documents_length.txt
\end{verbatim}


\section{Search Engine}

\par Some changes were introduced in the search engine to adapt to the requirements of the project. First, a new ranking system, tf-idf, was introduced to run along side the BM25 that was introduced in the previous project. The search function was modify to accept the number of results to return for the query.

\subsection{Tf-idf Ranking} \label{tf-idf}

The tf-idf ranking is simply ranking the documents by the results of their term frequency with respect to a document times the inverse document frequency of the term. This result in less useful results as pages where a certain terms appear for the once tends to be skewing its position in the top. BM25 seemed to be more impervious to this influence by repeating terms.

\subsubsection{With AITopics Document Frequencies}

The tf-idf ranking is the ranking scheme that was the most affected by the change of the document frequency of a term from the ConcordiaAI index to the AITopic index. Even though the project seems to hint in an improvement of the results, later in the report the opposite will be discussed. This might be due to the corpus upon which this technique was applied on.

\subsection{BM25 Ranking} \label{BM25}

\par The BM25 was the ranking scheme that returned the overall most useful results. 

\subsubsection{With AITopics Document Frequencies}

\par The BM25 ranking scheme seems to be impervious to the of the term document frequencies to the one collected from the AITopics website. The comparison between the original and the scheme modified with the document frequencies of AITopics is discussed in chapter.

\chapter{Queries Analysis}

\par Using the index compiled for ConcordiaAI and AIindex queries were designed and tested to try satisfy the following information needs.

\section{Which departments have AI research?}
\subsection{department deep learning research}\label{query-1}

\par In this sub-section the usefulness of the result $@10$, $@50$ and $@100$ will be discussed.
\subsubsection{Original BM25}\label{query-1-bm-25}

\par First, $P@10=4/10=0.4$. This result is suboptimal for any practical use as the user will be return more non-relevant results. After the analysis of the relevancy of the first 10 returns a relevant problem with the corpus was discover. It seems that the same is accessible by multiple URL which lead in duplication of documents.
\par Second, the usefulness of results $@50$ is similar to the previous results. A lot of duplicates are present in the result set. Hence, a lot of documents with the same content is rank with the same score.
\par Third, the results seems to be better $@100$ as the duplicates are found in the first $50$ and the remaining $50$ documents seem to be more relevant and diversified.
\par In conclusion, the word learning seems to be wildly used especially on a university website such as Concordia. It would be wise to search more toward machine learning and artificial intelligence.

\subsubsection{BM25 with AITopics Document Frequencies}\label{query-1-bm-25-aitopics}

\par It seems that the results $@10$, $@50$ and $@100$ are identical to \ref{query-1-bm-25}.
\par In conclusion, it seems that BM25 is impervious to the change in the document frequencies from the original corpus.

\subsubsection{Original Tf-Idf}\label{query-1-tf-idf}

\par First, $P@10=5/10=0.5$. This result is suboptimal for any practical use as the user will be return more non-relevant results. After the analysis of the relevancy of the first 10 returns a relevant problem with the corpus was discover. It seems that the same is accessible by multiple URL which lead in duplication of documents.
\par Second, the usefulness of results $@50$ is similar to the previous results. A lot of duplicates are present in the result set. Hence, a lot of documents with the same content is rank with the same score.
\par Third, the results seems to be better $@100$ as the duplicates are found in the first $50$ and the remaining $50$ documents seem to be more relevant and diversified.
\par In conclusion, the word learning seems to be wildly used especially on a university website such as Concordia. It would be wise to search more toward machine learning and artificial intelligence.

\subsubsection{Tf-Idf with AITopics Document Frequencies}\label{query-1-tf-idf-aitopics}

\par First, $P@10=5/10=0.5$. This result is suboptimal for any practical use as the user will be return more non-relevant results. After the analysis of the relevancy of the first 10 returns a relevant problem with the corpus was discover. It seems that the same is accessible by multiple URL which lead in duplication of documents.
\par Second, the usefulness of results $@50$ is similar to the previous results. A lot of duplicates are present in the result set. Hence, a lot of documents with the same content is rank with the same score.
\par Third, the results seems to be better $@100$ as the duplicates are found in the first $50$ and the remaining $50$ documents seem to be more relevant and diversified.
\par In conclusion, for this query the use of AITopics document frequencies does not seem to outweigh the cost of crawling the keywords. It would be better to clean the corpus and use the original document frequencies.

\subsection{department carrying out machine learning research}\label{query-2}

\subsubsection{Original BM25}\label{query-2-bm-25}

\par First, $P@10=10/10=1$. This query fares better on the corpus then \ref{query-1}. It seems that the term machine learning is used more often then deep learning. This might indicate that using less specific term in queries will result in better returns. The issue with duplicate documents is still present in the results, but it is less noticeable.
\par Second, results $@50$ shows less signs of the duplicate documents issue. The results are promising, but some documents are more about experts in the field then departments that are carrying out machine learning research. It's worth noting that usually these expert profiles have the department in which the 
\par Third, as results tends closer to $@100$ the become less relevant. This might be due to BM25 has ranked all the documents that was considered more relevant first and the remaining are document that fills partially the query. Most of the last results in the $@100$ only are relevant to the terms research and department.
\par In conclusion, this query shows promise for the corpus and last query should be built upon this one to be sure to have good results. The duplication seems to have less influence, but still compromise the first 10 to 25 results.

\subsubsection{BM25 with AITopics Document Frequencies}\label{query-2-bm-25-aitopics}

\par Similarly to \ref{query-1-bm-25-aitopics} the results are identical to \ref{query-2-bm-25}. This further demonstrate that BM25 is impervious to the change of the document frequencies.

\subsubsection{Original Tf-Idf}\label{query-2-tf-idf}

\par Similarly to \ref{query-1-tf-idf} the $P@10$ is not good. In this case, $P@10=3/10=0.3$ which is also a sub-optimal result. The word learning is producing good result for all tf-idf ranking scheme explored in this project.
\par After skimming through the results $@50$ the results are not useful. Some document are relevant but since the majority are non-relevant it makes it impractical for users to search through the results to determine which documents are relevant.
\par Results $@100$ are similar to the other results. It seems this query satisfy more an information need about pedagogical research.
\par In conclusion, this query does not fare well with Tf-idf ranking scheme. The corpus does contain results that is relevant to this query as seen in \ref{query-2-bm-25} which might indicate that tf-idf is not well suited for ranking complex queries.

\subsubsection{Tf-Idf with AITopics Document Frequencies}\label{query-2-tf-idf-aitopics}

\par Astonishingly, the use of the document frequencies from AITopics did contribute to improve the usefulness results $@10$. Even though the results are less precise then \ref{query-1-bm-25} they are still relevant to the query. $P@10=8/10=0.8$ which is a more useful result then \ref{query-2-tf-idf}.
\par While analyzing the results $@50$ a decrease of usefulness can be observed when the results goes beyond $@10$. It seems that the use of document frequencies from AITopics moved the more relevant document found in the $@100$ from \ref{query-2-tf-idf} but consequently move back the non-relevant document back.
\par Results $@100$ are similar to the results $@50$, that is some documents past the 50th rank are relevant but most are not relevant to the query, consequently not satisfying the information need. As stated previously, the use of AITopics document frequencies tends to rank the most relevant documents at higher rank.
\par The use of AITopics document frequencies is sensible in this scenario as it tend to sort relevant documents first before non-relevant. But this technique have limits that starts to show around $@50$ where the results start to be similar in relevance to the one found in \ref{query-2-tf-idf} for Tf-Idf without the AITopics document frequencies.

\subsection{department carrying out ai research}\label{query-3}

\subsubsection{Original BM25}\label{query-3-bm25}

\par Results $@10$ shows a precision of $6/10=0.6$. The results seem to indicate that using unique terms such as ai tend to improve the relevance of the documents return from this corpus. Note that the issue with duplicate is still present.
\par Results $@50$ shows a decrease in usefulness crossed the 10th rank. This could be understandable as the abbreviation of the term ai is a short form of artificial intelligence. Since Concordia website target audience in higher education the use of abbreviation such as ai tends to be use less then other news outlet.
\par Results ranking between $@50$ and $@100$ tends to be completely non-relevant to the information for which the query is trying to satisfy. This further demonstrate that the use of the term ai use not as common as artificial intelligence. 
\par In conclusion, the query tends to satisfy the information $@10$ but tends to drift as we increase in rank. This query helps filter out the documents that contains the term 'artificial intelligence' at the cost of numbers of relevant documents retrieved.

\subsubsection{BM25 with AITopics Document Frequencies}\label{query-3-bm25-aitopics}

\par Similarly to the BM25 from \ref{query-2-bm-25-aitopics} the results are identical to the original BM25 from \ref{query-3-bm25}. This further demonstrate that BM25 is impervious to the change of the document frequencies.

\subsubsection{Original Tf-Idf}\label{query-3-tf-idf}

\par Results $@10$ shows a precision of $8/10=0.8$. The results seem to indicate that using unique terms such as ai tend to improve the relevance of the documents return from this corpus. Note that the issue with duplicate is still present.
\par Results $@50$ shows a decrease in usefulness crossed the 10th rank. This could be understandable as the abbreviation of the term ai is a short form of artificial intelligence. Since Concordia website target audience in higher education the use of abbreviation such as ai tends to be use less then other news outlet.
\par Results ranking between $@50$ and $@100$ tends to be completely non-relevant to the information for which the query is trying to satisfy. This further demonstrate that the use of the term ai use not as common as artificial intelligence. 
\par In conclusion, the query tends to satisfy the information $@10$ but tends to drift as we increase in rank. This query helps filter out the documents that contains the term 'artificial intelligence' at the cost of numbers of relevant documents retrieved.

\subsubsection{Tf-Idf with AITopics Document Frequencies} \label{query-3-tf-idf-aitopics}

\par The use of the document frequencies from AITopics did contribute to improve the usefulness results $@10$. Even though the results are less precise then BM25 from \ref{query-3-bm25} they are still relevant to the query. $P@10=8/10=0.8$ which is a more useful result then from Tf-idf from \ref{query-3-tf-idf}.
\par While analyzing the results $@50$ a decrease of usefulness can be observed when the results goes beyond $@10$. It seems that the use of document frequencies from AITopics moved the more relevant document found in the $@100$ from \ref{query-2-tf-idf} but consequently move back the non-relevant document back.
\par Results $@100$ are similar to the results $@50$, that is some documents past the 50th rank are relevant but most are not relevant to the query, consequently not satisfying the information need. As stated previously, the use of AITopics document frequencies tends to rank the most relevant documents at higher rank.
\par The use of AITopics document frequencies is sensible in this scenario as it tend to sort relevant documents first before non-relevant. But this technique have limits that starts to show around $@50$ where the results start to be similar in relevance to the one found in \ref{query-2-tf-idf} for Tf-Idf without the AITopics document frequencies.

\section{Which researchers are working on AI research?}

\subsection{ai researchers}\label{query-4}

\subsubsection{Original BM25}\label{query-4-bm25}

\par Results $@10$ shows a precision of $10/10=1$. The results seem to indicate that using unique terms such as ai tend to improve the relevance of the documents return from this corpus. Note that the issue with duplicate is still present.
\par Results $@50$ shows a decrease in usefulness crossed the 10th rank. This could be understandable as the abbreviation of the term ai is a short form of artificial intelligence. Since Concordia website target audience in higher education the use of abbreviation such as ai tends to be use less then other news outlet.
\par Results ranking between $@50$ and $@100$ tends to be completely non-relevant to the information for which the query is trying to satisfy. This further demonstrate that the use of the term ai use not as common as artificial intelligence. 
\par In conclusion, the query tends to satisfy the information $@10$ but tends to drift as we increase in rank. This query helps filter out the documents that contains the term 'artificial intelligence' at the cost of numbers of relevant documents retrieved. Furthermore, simpler queries tends to have better result. This might be due to the lack of words for the results to drift on.

\subsubsection{BM25 with AITopics Document Frequencies}\label{query-4-bm25-aitopics}

\par Similarly to the BM25 from \ref{query-2-bm-25-aitopics} the results are identical to the original BM25 from \ref{query-4-bm25}. This further demonstrate that BM25 is impervious to the change of the document frequencies.

\subsubsection{Original Tf-Idf}\label{query-4-tf-idf}

\par Results $@10$ shows a precision of $10/10=1$. The results seem to indicate that using unique terms such as ai tend to improve the relevance of the documents return from this corpus. Note that the issue with duplicate is still present.
\par Results $@50$ shows a decrease in usefulness crossed the 10th rank. This could be understandable as the abbreviation of the term ai is a short form of artificial intelligence. Since Concordia website target audience in higher education the use of abbreviation such as ai tends to be use less then other news outlet.
\par Results ranking between $@50$ and $@100$ tends to be completely non-relevant to the information for which the query is trying to satisfy. This further demonstrate that the use of the term ai use not as common as artificial intelligence. 
\par In conclusion, the query tends to satisfy the information $@10$ but tends to drift as we increase in rank. This query helps filter out the documents that contains the term 'artificial intelligence' at the cost of numbers of relevant documents retrieved.

\subsubsection{Tf-Idf with AITopics Document Frequencies} \label{query-4-tf-idf-aitopics}

\par The use of the document frequencies from AITopics did contribute to did not improve the usefulness results $@10$. Since both the results for tf-idf and BM25 from \ref{query-4-bm25} they are still relevant to the query. $P@10=10/10=1$ which is a more useful result then from Tf-idf from \ref{query-4-tf-idf}.
\par While analyzing the results $@50$ a decrease of usefulness can be observed when the results goes beyond $@10$. It seems that the use of document frequencies from AITopics moved the more relevant document found in the $@100$ from \ref{query-4-tf-idf} but consequently move back the non-relevant document back.
\par Results $@100$ are similar to the results $@50$, that is some documents past the 50th rank are relevant but most are not relevant to the query, consequently not satisfying the information need. As stated previously, the use of AITopics document frequencies tends to rank the most relevant documents at higher rank.
\par The use of AITopics document frequencies is sensible in this scenario as it tend to sort relevant documents first before non-relevant. But this technique have limits that starts to show around $@50$ where the results start to be similar in relevance to the one found in \ref{query-2-tf-idf} for Tf-Idf without the AITopics document frequencies.

\subsection{concordia chair machine learning}\label{query-5}

\subsubsection{Original BM25}\label{query-5-bm25}

\par Results $@10$ shows a precision of $7/10=0.7$. The results seem to indicate that using more specific terms such as 'research chair' tend to improve the relevance of the documents return from this corpus. Note that the issue with duplicate is still present.
\par Results $@50$ shows a decrease in usefulness crossed the 10th rank. This could be understandable as other term then research chair could be used. Since no query expansion is being done then this limit the results being returned to only the ones with research chair present in them.
\par Results ranking between $@50$ and $@100$ tends to be completely non-relevant to the information for which the query is trying to satisfy. Unfortunately the term research as a wide use in the english language and tends to drift the results from the informaton need. 
\par In conclusion, the query tends to satisfy the information $@10$ but tends to drift as we increase in rank. This query helps searching for results where the term 'ai' or 'researchers' was not used in the document.

\subsubsection{BM25 with AITopics Document Frequencies}\label{query-5-bm25-aitopics}

\par Similarly to the BM25 from \ref{query-2-bm-25-aitopics} the results are identical to the original BM25 from \ref{query-3-bm25}. This further demonstrate that BM25 is impervious to the change of the document frequencies.

\subsubsection{Original Tf-Idf}\label{query-5-tf-idf}

\par Results $@10$ shows a precision of $0/10=0$. The results seem to indicate that using the tf-idf ranking scheme made the results drift away from the information need. It seems that tf-idf perform better on small simple queries. Note that the issue with duplicate is still present.
\par Results $@50$ shows a decrease in usefulness crossed the 10th rank. This could be understandable as the abbreviation of the term ai is a short form of artificial intelligence. Since Concordia website target audience in higher education the use of abbreviation such as ai tends to be use less then other news outlet.
\par Results ranking between $@50$ and $@100$ tends to be completely non-relevant to the information for which the query is trying to satisfy. This further demonstrate that the use of the term ai use not as common as artificial intelligence. 
\par In conclusion, using this ranking scheme with this query does not produce useful results.

\subsubsection{Tf-Idf with AITopics Document Frequencies} \label{query-5-tf-idf-aitopics}

\par The use of the document frequencies from AITopics did contribute to improve the usefulness results $@10$. Even though the results are less precise then BM25 from \ref{query-5-bm25} they are still relevant to the query. $P@10=10/10=0.8$ which is a more useful result then from Tf-idf from \ref{query-5-tf-idf}.
\par While analyzing the results $@50$ a decrease of usefulness can be observed when the results goes beyond $@10$. It seems that the use of document frequencies from AITopics moved the more relevant document found in the $@100$ from \ref{query-5-tf-idf} but consequently move back the non-relevant document.
\par Results $@100$ are similar to the results $@50$, that is some documents past the 50th rank are relevant but most are not relevant to the query, consequently not satisfying the information need. As stated previously, the use of AITopics document frequencies tends to rank the most relevant documents at higher rank.
\par The use of AITopics document frequencies is sensible in this scenario as it tend to sort relevant documents first before non-relevant. But this technique have limits that starts to show around $@50$ where the results start to be similar in relevance to the one found in \ref{query-5-tf-idf} for Tf-Idf without the AITopics document frequencies.

\subsection{thesis machine learning}\label{query-6}

\subsubsection{Original BM25}\label{query-6-bm25}

\par Results $@10$ shows a precision of $6/10=0.6$. The results seem to indicate that using unique terms such as ai tend to improve the relevance of the documents return from this corpus. Note that the issue with duplicate is still present.
\par Results $@50$ shows a decrease in usefulness crossed the 10th rank. This could be understandable as the abbreviation of the term ai is a short form of artificial intelligence. Since Concordia website target audience in higher education the use of abbreviation such as ai tends to be use less then other news outlet.
\par Results ranking between $@50$ and $@100$ tends to be completely non-relevant to the information for which the query is trying to satisfy. This further demonstrate that the use of the term ai use not as common as artificial intelligence. 
\par In conclusion, the query tends to satisfy the information $@10$ but tends to drift as we increase in rank. This query helps filter out the documents that contains the term 'artificial intelligence' at the cost of numbers of relevant documents retrieved.

\subsubsection{BM25 with AITopics Document Frequencies}\label{query-6-bm25-aitopics}

\par Similarly to the BM25 from \ref{query-5-bm25-aitopics} the results are identical to the original BM25 from \ref{query-3-bm25}. This further demonstrate that BM25 is impervious to the change of the document frequencies.

\subsubsection{Original Tf-Idf}\label{query-6-tf-idf}

\par Results $@10$ shows a precision of $0/10=0$. The results seem to indicate that using using this query with tf-idf on this corpus makes the results drift from the information need. Note that the issue with duplicate is still present.
\par Results $@50$ shows similar result to $@10$. As hypothesize earlier tf-idf tends to perform better on simple and short query. This query have terms that are wildly used in an academic. Hence, this ranking scheme drifts on the term 'chair', 'concordia' and 'learning'.
\par Results ranking between $@50$ and $@100$ tends to be completely non-relevant to the information for which the query is trying to satisfy.
\par In conclusion, the original tf-idf ranking scheme does not fare well with the query. The query as terms that will make the ranking drifts from the information need. As explained, using specific term and short queries makes the tf-idf not drift.

\subsubsection{Tf-Idf with AITopics Document Frequencies} \label{query-6-tf-idf-aitopics}

\par The use of the document frequencies from AITopics did contribute to improve the usefulness results $@10$. Even though the results are less precise then BM25 from \ref{query-5-bm25} they are still relevant to the query. $P@10=8/10=0.8$ which is a more useful result then from Tf-idf from \ref{query-3-tf-idf}.
\par While analyzing the results $@50$ a decrease of usefulness can be observed when the results goes beyond $@10$. It seems that the use of document frequencies from AITopics moved the more relevant document found in the $@100$ from \ref{query-2-tf-idf} but consequently move back the non-relevant document back.
\par Results $@100$ are similar to the results $@50$, that is some documents past the 50th rank are relevant but most are not relevant to the query, consequently not satisfying the information need. As stated previously, the use of AITopics document frequencies tends to rank the most relevant documents at higher rank.
\par The use of AITopics document frequencies is sensible in this scenario as it tend to sort relevant documents first before non-relevant. But this technique have limits that starts to show around $@50$ where the results start to be similar in relevance to the one found in \ref{query-2-tf-idf} for Tf-Idf without the AITopics document frequencies.

\section{What AI research is being conducted at Concordia?}

\subsection{nlp research at concordia}\label{query-7}

\subsubsection{Original BM25}\label{query-7-bm25}

\par Results $@10$ shows a precision of $9/10=0.9$. The results seem to further demonstrate that using unique terms such as nlp tend to improve the relevance of the documents return from this corpus. Note that the issue with duplicate is still present.
\par Results $@50$ shows a decrease in usefulness crossed the 10th rank. This could be understandable as the abbreviation of the term nlp could be less used then its counter part `natural language processing'. Since Concordia website target audience in higher education the use of abbreviation such as nlp tends to be use less then other news outlet.
\par Results ranking between $@50$ and $@100$ tends to be completely non-relevant to the information for which the query is trying to satisfy. The last results tend to only contain one of the terms from the query making it less likely to satisfy the information need. 
\par In conclusion, the query tends to satisfy the information $@10$ but tends to drift as we increase in rank. This query helps filter out the documents that contains the term 'language' and 'natural' two widely use term in academia. Yet, this comes at the cost of numbers of relevant documents retrieved.

\subsubsection{BM25 with AITopics Document Frequencies}\label{query-7-bm25-aitopics}

\par Similarly to the BM25 from \ref{query-6-bm25-aitopics} the results are identical to the original BM25 from \ref{query-7-bm25}. This further demonstrate that BM25 is impervious to the change of the document frequencies.

\subsubsection{Original Tf-Idf}\label{query-7-tf-idf}

\par The ranking scheme tf-idf shows a $P@10=0/10=0$. This precision foreshadows the remaining result return by this scheme. In brief, this ranking scheme does not return results that satisfies the information need.

\subsubsection{Tf-Idf with AITopics Document Frequencies} \label{query-7-tf-idf-aitopics}

\par Similarly to the Tf-idf ranking for \ref{query-7-tf-idf} replacing the document frequencies for the ones calculated from AITopics resulted in no improvement to the usefulness of the results. 

\subsection{neural network at concordia}\label{query-8}

\subsubsection{Original BM25}\label{query-8-bm25}

\par Results $@10$ shows a precision of $9/10=0.9$. The results seem to indicate that using unique terms such as ai tend to improve the relevance of the documents return from this corpus. Note that the issue with duplicate is still present.
\par Results $@50$ shows a decrease in usefulness crossed the 10th rank. This could be understandable as the term 'neural' network is widely use in neuroscience. Yet, BM25 was able to rank the relevant documents first.
\par Results ranking between $@50$ and $@100$ tends to be completely non-relevant to the information for which the query is trying to satisfy. As mentioned neural network is a specific topic in artificial intelligence and thus as the rank increase more and more documents are returned concerning neuroscience. 
\par In conclusion, the query tends to satisfy the information $@10$ but tends to drift as we increase in rank. The BM25 ranking scheme does a efficient outcome in ranking the relevant document first.

\subsubsection{BM25 with AITopics Document Frequencies}\label{query-8-bm25-aitopics}

\par Similarly to the BM25 from \ref{query-7-bm25-aitopics} the results are identical to the original BM25 from \ref{query-7-bm25}. This further demonstrate that BM25 is impervious to the change of the document frequencies.

\subsubsection{Original Tf-Idf}\label{query-8-tf-idf}

\par The tf-idf ranking scheme did not fare well with this query. With a $P@10=0$ and the usefulness of the results up to $@110$ is low we had to conclude that the query is to intricate for this ranking scheme.

\subsubsection{Tf-Idf with AITopics Document Frequencies} \label{query-8-tf-idf-aitopics}

\par The use of the document frequencies from AITopics did contribute to improve the usefulness results $@10$. Even though the results are less precise then BM25 from \ref{query-7-bm25} they are still relevant to the query. $P@10=3/10=0.3$ which is a more useful result then from Tf-idf from \ref{query-8-tf-idf}.
\par While analyzing the results $@50$ a decrease of usefulness can be observed when the results goes beyond $@10$. It seems that the use of document frequencies from AITopics moved the more relevant document found in the $@100$ from \ref{query-8-tf-idf} but consequently move back the non-relevant document back.
\par Results $@100$ are similar to the results $@50$, that is some documents past the 50th rank are relevant but most are not relevant to the query, consequently not satisfying the information need. As stated previously, the use of AITopics document frequencies tends to rank the most relevant documents at higher rank.
\par The use of AITopics document frequencies is sensible in this scenario as it tend to sort relevant documents first before non-relevant. But this technique have limits that starts to show around $@50$ where the results start to be similar in relevance to the one found in \ref{query-8-tf-idf} for Tf-Idf without the AITopics document frequencies.

\subsection{pattern recognition research at concordia}\label{query-9}

\subsubsection{Original BM25}\label{query-9-bm25}

\par Results $@10$ shows a precision of $0/10=0.6$. The results seem to indicate that this query did not return any relevant results for the first 10 results. Note that the duplicate issue is still a problem.
\par Results $@50$ shows no increase in usefulness. Strangely even the CENPARMI appears less then expected in the results.
\par Results ranking between $@50$ and $@100$ are as completely non-relevant to the information for which the query is trying to satisfy. This further demonstrate that this query drifts.
\par In conclusion, this query should not be considered as a useful query.

\subsubsection{BM25 with AITopics Document Frequencies}\label{query-9-bm25-aitopics}

\par Similarly to the BM25 from \ref{query-2-bm-25-aitopics} the results are identical to the original BM25 from \ref{query-3-bm25}. This further demonstrate that BM25 is impervious to the change of the document frequencies.

\subsubsection{Original Tf-Idf}\label{query-9-tf-idf}

\par These result are as scattered as for the BM25 from \ref{query-9-bm25}. The results were scattered to a certain degree that the user would have a hard time to retrieve any useful information from the result set.

\subsubsection{Tf-Idf with AITopics Document Frequencies} \label{query-9-tf-idf-aitopics}

\par Particularly, this was the only query that return the same result for Tf-idf with AITopics Document Frequencies and the original Tf-idf. This is peculiar situation that might be explained by none of the term being found in the concept tags of AITopics. 

\chapter{Answers}

\section{Which departments have AI research?}

\subsection{Mine}

\begin{itemize}
    \item Department of Computer Science and Software Engineering (CSSE)
    \item Concordia Institute for Information Systems Engineering (CIISE)
    \item Computational Linguistics at Concordia (CLaC) Laboratory
    \item Centre for Pattern Recognition and Machine Intelligence
    \item Department of Mathematics \& Statistics
    \item Department of Studio Arts
    \item Concordia Institute of Aerospace Design and Innovation
    \item Design and Computation Arts
\end{itemize}

\subsection{Daniel Stroppolo}

\begin{itemize}
    \item Building Engineering
    \item Computer Engineering
    \item Information Systems Engineering
    \item Computer Science
\end{itemize}

\subsection{Comparaison}

\par Seems that Daniel's answers were mostly related to mostly Engineering. This might be due to the use of only the term 'artificial intelligence' in his query. When the term 'machine learning' in queries helped to broaden the results to other STEM departments and even fine arts.

\section{Which researchers are working on AI research?}

\subsection{Mine}

\begin{itemize}
    \item Xavier-Henri Hervé
    \item Sydney Swaine-Simon
    \item Charles Onu
    \item Sabine Bergler
    \item Anne Martel
    \item Jason Edward Lewis
    \item Dr. C. Y. Suen
    \item Hassan Rivaz
    \item Michael Hallett
    \item Eromonsele Samuel Oboh
    \item Nizar Bouguila
    \item Dr. T. Fevens
    \item Dr. O. Ormandieva
    \item Dr. L. Kosseim
    \item Dr. Marie-Jean Meurs
    \item Dr. W. Lucia
    \item Dr. J. Bentahar
    \item Dr. C. Poullis
    \item Dr. P. Rigby
    \item [Many more]    
\end{itemize}

\subsection{Daniel Stroppolo}

\begin{itemize}
    \item Dr. Leila Kosseim
\end{itemize}

\subsection{Comparison}

\par Seems that Daniel's answers were mostly related to mostly one individual. This might be due to the use of only the term 'artificial intelligence' in his queries. When the term 'machine learning' and 'neural network' in queries helped to broaden the results to other STEM departments and even fine arts. 

\section{What AI research is being conducted at Concordia?}

\subsection{Mine}

\begin{itemize}
    \item Tool that analyzes informal online writing
    \item Software architecture that accelerates research and boosts quality of writing
    \item Neural Networks as Pseudorandom Number Generators
    \item Neural Network Approaches to Implicit Discourse Relation Recognition
\end{itemize}

\subsection{Daniel Stroppolo}

\begin{itemize}
    \item Pattern recognition (various theses)
    \item Bioinformatics and software supporting it
    \item Smart buildings
    \item Linguistics
    \item Cyber Security
\end{itemize}

\subsection{Comparison}

\par Daniel was able to have broader results on the research conducted at Concordia that uses artificial intelligence. 

\chapter{Difficulties}

\par One of the difficulty that was encountered in the project was the loop found in the crawling of the Concordia website
\par Another difficulty that was encountered that some of the documents accidentally contains the term artificial intelligence without being relevant to these term. This is due to how the Concordia website was scraped and the title of news article that are found on multiple page was wrongly assumed to be part of the document. See below an example of news headlines that skewed some documents for the term 'artificial intelligence'.
\begin{center}
    \includegraphics[width=\textwidth]{difficulty1.png}
\end{center}
\par In conclusion, lack of crawling/scraping proved to be any issue that both I and my partner encountered in the project. If something should be improved upon for any next iteration it would be to make specialized rule for each department and make sure that only the right information is collected from the website.